{
  "expanded_description": "The line of best fit (also called a trend line or regression line) is a straight line that best represents the data on a scatter plot. It summarizes the relationship between two variables, allowing us to make predictions and quantify the strength of the linear relationship. The most common method for finding this line is linear regression, which minimizes the sum of squared vertical distances between the data points and the line. Understanding how to find, interpret, and use the line of best fit is essential for predictive modeling and data analysis in fields ranging from economics to environmental science.",
  
  "core_concept": {
    "principle": "The line of best fit has the form $y = mx + b$ where:<br><br>• $m$ is the slope - the rate of change in y for each 1-unit increase in x<br>• $b$ is the y-intercept - the predicted y when x = 0<br><br>Methods to find the line:<br><br>1. **Estimation by eye**: Draw a line that balances points above and below<br>2. **Median-median line**: Robust method using medians of three groups<br>3. **Least squares regression**: Mathematical method minimizing squared errors (most common)<br><br>The correlation coefficient $r$ measures the strength and direction of the linear relationship.",
    
    "explanation": "Imagine your scatter plot is a cloud of points. The line of best fit is like the spine of that cloud - it goes through the middle, showing the general trend. Points above the line are higher than predicted; points below are lower. This line is your data's story in a nutshell, letting you predict new values and see how strongly two variables are connected. It's like finding the main street through a scattered neighborhood.",
    
    "image": {
      "src": "images/unit14/line_of_best_fit_overview.png",
      "alt": "Scatter plot with line of best fit showing points above and below the line",
      "caption": "Figure 14.7.1: The line of best fit summarizes the linear relationship between variables."
    }
  },

  "sections": [
    {
      "section_title": "14.7.1 Estimating the Line of Best Fit by Eye",
      
      "introduction": "When precision isn't critical, you can estimate a trend line by drawing a line that roughly balances the points.",
      
      "introduction_image": {
        "src": "images/unit14/estimate_by_eye_intro.png",
        "alt": "Estimating line of best fit visually",
        "caption": "Figure 14.7.2: Draw a line that balances points above and below."
      },
      
      "key_concept": {
        "definition": "To estimate a line of best fit by eye:<br><br>1. Look at the overall trend of the points<br>2. Draw a line that follows the direction of the data<br>3. Aim to have roughly the same number of points above and below the line<br>4. The line should pass through the \"center\" of the data<br>5. Adjust so the vertical distances above and below seem balanced<br><br>This method is quick but subjective - different people may draw slightly different lines.",
        
        "context": "This method works well for getting a rough idea of the trend or when you need a quick visualization without calculations.",
        
        "image": {
          "src": "images/unit14/estimate_by_eye_steps.png",
          "alt": "Steps for estimating trend line by eye",
          "caption": "Figure 14.7.3: Visual estimation process."
        }
      },

      "worked_examples": [
        {
          "title": "Estimating by Eye",
          
          "image": {
            "src": "images/unit14/estimate_by_eye_practice.png",
            "alt": "Practice estimating by eye",
            "caption": "Figure 14.7.4: Draw an estimated line of best fit for this data."
          },
          
          "problem": "Given points: (1,2), (2,3), (3,5), (4,6), (5,7), (6,8), (7,10), (8,11). Estimate a line of best fit by eye and approximate its equation.",
          
          "step_by_step": [
            {
              "step": "Plot points mentally",
              "explanation": "Points show upward trend",
              "calculation": ""
            },
            {
              "step": "Visualize center line",
              "explanation": "Line roughly through middle of points",
              "calculation": "Might pass near (2,3.5) and (7,10)"
            },
            {
              "step": "Estimate slope",
              "explanation": "Rise/run between these points",
              "calculation": "Slope ≈ (10-3.5)/(7-2) = 6.5/5 = 1.3"
            },
            {
              "step": "Estimate y-intercept",
              "explanation": "Extend line back to x=0",
              "calculation": "Using point-slope: y - 3.5 = 1.3(x - 2), at x=0, y ≈ 3.5 - 2.6 = 0.9"
            },
            {
              "step": "Estimated equation",
              "explanation": "y ≈ 1.3x + 0.9",
              "calculation": ""
            }
          ],
          
          "final_answer": "Estimated line of best fit: y ≈ 1.3x + 0.9",
          "concept_applied": "Draw line that balances points, then estimate slope and intercept from two points on the line."
        }
      ],

      "image": {
        "src": "images/unit14/estimate_by_eye_summary.png",
        "alt": "Summary of estimating line by eye",
        "caption": "Figure 14.7.5: Visual estimation summary."
      }
    },

    {
      "section_title": "14.7.2 The Median-Median Line",
      
      "introduction": "The median-median line is a robust method that uses medians to find a line resistant to outliers.",
      
      "introduction_image": {
        "src": "images/unit14/median_median_intro.png",
        "alt": "Median-median line method",
        "caption": "Figure 14.7.6: Using medians of three groups to find a resistant line."
      },
      
      "key_concept": {
        "definition": "Steps for the median-median line:<br><br>1. Order data by x-values and divide into three equal groups (left, middle, right)<br>2. Find the median x and median y for each group: (x₁, y₁), (x₂, y₂), (x₃, y₃)<br>3. Use the left and right median points to find a preliminary slope: $m = \\frac{y_3 - y_1}{x_3 - x_1}$<br>4. Find the intercept using all three points: $b = \\frac{(y_1 - m x_1) + (y_2 - m x_2) + (y_3 - m x_3)}{3}$<br><br>This line is resistant to outliers because medians are used.",
        
        "context": "This method is sometimes called the \"resistant line\" because it's not swayed by extreme values as much as least squares regression.",
        
        "image": {
          "src": "images/unit14/median_median_steps.png",
          "alt": "Step-by-step median-median line calculation",
          "caption": "Figure 14.7.7: Median-median line process."
        }
      },

      "worked_examples": [
        {
          "title": "Finding the Median-Median Line",
          
          "image": {
            "src": "images/unit14/median_median_practice.png",
            "alt": "Practice median-median line",
            "caption": "Figure 14.7.8: Find the median-median line for the data."
          },
          
          "problem": "Data: (1,2), (2,4), (3,5), (4,4), (5,7), (6,8), (7,9), (8,10), (9,11). Find the median-median line.",
          
          "step_by_step": [
            {
              "step": "Order and divide into groups",
              "explanation": "9 points → 3 groups of 3",
              "calculation": "Left: (1,2),(2,4),(3,5)<br>Middle: (4,4),(5,7),(6,8)<br>Right: (7,9),(8,10),(9,11)"
            },
            {
              "step": "Find median points",
              "explanation": "Median x and y for each group",
              "calculation": "Left: median x=2, median y=4 → (2,4)<br>Middle: median x=5, median y=7 → (5,7)<br>Right: median x=8, median y=10 → (8,10)"
            },
            {
              "step": "Calculate slope",
              "explanation": "Using left and right median points",
              "calculation": "$m = \\frac{10-4}{8-2} = \\frac{6}{6} = 1$"
            },
            {
              "step": "Calculate intercept contributions",
              "explanation": "$y_1 - m x_1 = 4 - 1(2) = 2$<br>$y_2 - m x_2 = 7 - 1(5) = 2$<br>$y_3 - m x_3 = 10 - 1(8) = 2$",
              "calculation": ""
            },
            {
              "step": "Find intercept",
              "explanation": "Average the three values",
              "calculation": "$b = \\frac{2+2+2}{3} = 2$"
            },
            {
              "step": "Write equation",
              "explanation": "$y = mx + b$",
              "calculation": "$y = 1x + 2$ or $y = x + 2$"
            }
          ],
          
          "final_answer": "Median-median line: $y = x + 2$",
          "concept_applied": "Use median points from three groups to find a resistant line."
        }
      ],

      "image": {
        "src": "images/unit14/median_median_summary.png",
        "alt": "Summary of median-median line method",
        "caption": "Figure 14.7.9: Median-median line summary."
      }
    },

    {
      "section_title": "14.7.3 Least Squares Regression Line",
      
      "introduction": "The least squares regression line is the most common and mathematically precise method for finding the line of best fit.",
      
      "introduction_image": {
        "src": "images/unit14/least_squares_intro.png",
        "alt": "Least squares concept",
        "caption": "Figure 14.7.10: Least squares minimizes the sum of squared vertical distances."
      },
      
      "key_concept": {
        "definition": "The least squares regression line minimizes the sum of squared vertical distances (residuals) between data points and the line. Formulas:<br><br>$$\\text{slope: } m = \\frac{\\sum(x - \\bar{x})(y - \\bar{y})}{\\sum(x - \\bar{x})^2}$$<br><br>$$\\text{intercept: } b = \\bar{y} - m\\bar{x}$$<br><br>Where $\\bar{x}$ and $\\bar{y}$ are the means of x and y. This line has the important property that the sum of residuals equals zero.",
        
        "context": "This is the standard method used by calculators and statistical software. The line is sometimes written as $\\hat{y} = mx + b$ where $\\hat{y}$ (y-hat) indicates a predicted value.",
        
        "image": {
          "src": "images/unit14/least_squares_formula.png",
          "alt": "Least squares formulas",
          "caption": "Figure 14.7.11: Slope and intercept formulas."
        }
      },

      "worked_examples": [
        {
          "title": "Calculating Least Squares Regression Line",
          
          "image": {
            "src": "images/unit14/least_squares_practice.png",
            "alt": "Practice least squares calculation",
            "caption": "Figure 14.7.12: Find the least squares regression line."
          },
          
          "problem": "Data: (1,2), (2,3), (3,5), (4,4), (5,6). Find the least squares regression line.",
          
          "step_by_step": [
            {
              "step": "Calculate means",
              "explanation": "$\\bar{x} = \\frac{1+2+3+4+5}{5} = \\frac{15}{5} = 3$",
              "calculation": "$\\bar{y} = \\frac{2+3+5+4+6}{5} = \\frac{20}{5} = 4$"
            },
            {
              "step": "Create table of deviations",
              "explanation": "Calculate $(x-\\bar{x})$, $(y-\\bar{y})$, products, and squares",
              "calculation": "| x | y | x-3 | y-4 | (x-3)(y-4) | (x-3)² |\n| 1 | 2 | -2 | -2 | 4 | 4 |\n| 2 | 3 | -1 | -1 | 1 | 1 |\n| 3 | 5 | 0 | 1 | 0 | 0 |\n| 4 | 4 | 1 | 0 | 0 | 1 |\n| 5 | 6 | 2 | 2 | 4 | 4 |"
            },
            {
              "step": "Sum columns",
              "explanation": "Add the last two columns",
              "calculation": "$\\sum(x-\\bar{x})(y-\\bar{y}) = 4+1+0+0+4 = 9$<br>$\\sum(x-\\bar{x})^2 = 4+1+0+1+4 = 10$"
            },
            {
              "step": "Calculate slope",
              "explanation": "$m = \\frac{\\sum(x-\\bar{x})(y-\\bar{y})}{\\sum(x-\\bar{x})^2}$",
              "calculation": "$m = \\frac{9}{10} = 0.9$"
            },
            {
              "step": "Calculate intercept",
              "explanation": "$b = \\bar{y} - m\\bar{x}$",
              "calculation": "$b = 4 - 0.9(3) = 4 - 2.7 = 1.3$"
            },
            {
              "step": "Write equation",
              "explanation": "$\\hat{y} = mx + b$",
              "calculation": "$\\hat{y} = 0.9x + 1.3$"
            }
          ],
          
          "final_answer": "Least squares regression line: $\\hat{y} = 0.9x + 1.3$",
          "concept_applied": "Use formulas to calculate slope and intercept that minimize squared residuals."
        }
      ],

      "image": {
        "src": "images/unit14/least_squares_summary.png",
        "alt": "Summary of least squares regression",
        "caption": "Figure 14.7.13: Least squares regression summary."
      }
    },

    {
      "section_title": "14.7.4 The Correlation Coefficient r",
      
      "introduction": "The correlation coefficient r measures the strength and direction of a linear relationship.",
      
      "introduction_image": {
        "src": "images/unit14/correlation_coefficient_intro.png",
        "alt": "Correlation coefficient values",
        "caption": "Figure 14.7.14: r ranges from -1 to +1, indicating strength and direction."
      },
      
      "key_concept": {
        "definition": "The correlation coefficient $r$ ranges from -1 to +1:<br><br>• $r = +1$: Perfect positive linear correlation<br>• $r = -1$: Perfect negative linear correlation<br>• $r = 0$: No linear correlation<br><br>Formula: $$r = \\frac{\\sum(x-\\bar{x})(y-\\bar{y})}{\\sqrt{\\sum(x-\\bar{x})^2 \\sum(y-\\bar{y})^2}}$$<br><br>Guidelines for strength:<br>• $|r| > 0.8$: Strong correlation<br>• $0.5 < |r| < 0.8$: Moderate correlation<br>• $0.3 < |r| < 0.5$: Weak correlation<br>• $|r| < 0.3$: Very weak or no correlation",
        
        "context": "Note: r only measures linear relationships. Two variables could have a perfect curved relationship but r = 0.",
        
        "image": {
          "src": "images/unit14/correlation_coefficient_examples.png",
          "alt": "Examples of different r values",
          "caption": "Figure 14.7.15: Scatter plots with different correlation coefficients."
        }
      },

      "worked_examples": [
        {
          "title": "Calculating Correlation Coefficient",
          
          "image": {
            "src": "images/unit14/correlation_coefficient_practice.png",
            "alt": "Practice calculating r",
            "caption": "Figure 14.7.16: Calculate r for the data."
          },
          
          "problem": "Using the same data: (1,2), (2,3), (3,5), (4,4), (5,6), calculate the correlation coefficient r.",
          
          "step_by_step": [
            {
              "step": "Recall previous calculations",
              "explanation": "From earlier, we have:",
              "calculation": "$\\bar{x}=3$, $\\bar{y}=4$<br>$\\sum(x-\\bar{x})(y-\\bar{y}) = 9$<br>$\\sum(x-\\bar{x})^2 = 10$"
            },
            {
              "step": "Calculate $\\sum(y-\\bar{y})^2$",
              "explanation": "Deviations in y: (2-4)=-2, (3-4)=-1, (5-4)=1, (4-4)=0, (6-4)=2",
              "calculation": "$\\sum(y-\\bar{y})^2 = 4+1+1+0+4 = 10$"
            },
            {
              "step": "Apply formula",
              "explanation": "$r = \\frac{9}{\\sqrt{10 \\times 10}}$",
              "calculation": "$r = \\frac{9}{\\sqrt{100}} = \\frac{9}{10} = 0.9$"
            },
            {
              "step": "Interpret",
              "explanation": "r = 0.9 indicates strong positive correlation",
              "calculation": ""
            }
          ],
          
          "final_answer": "$r = 0.9$, indicating a strong positive linear correlation.",
          "concept_applied": "Correlation coefficient measures strength and direction of linear relationship."
        }
      ],

      "image": {
        "src": "images/unit14/correlation_coefficient_summary.png",
        "alt": "Summary of correlation coefficient",
        "caption": "Figure 14.7.17: Correlation coefficient summary."
      }
    },

    {
      "section_title": "14.7.5 Using the Line for Predictions",
      
      "introduction": "Once we have a line of best fit, we can use it to predict y-values for given x-values.",
      
      "introduction_image": {
        "src": "images/unit14/predictions_intro.png",
        "alt": "Making predictions with regression line",
        "caption": "Figure 14.7.18: Use the line to predict y for new x values."
      },
      
      "key_concept": {
        "definition": "To make a prediction using the regression line $\\hat{y} = mx + b$:<br><br>1. Substitute the x-value into the equation<br>2. Calculate the corresponding $\\hat{y}$<br>3. Be aware of the prediction range - extrapolating far beyond the data can be unreliable<br><br>**Interpolation**: Predicting within the range of observed x-values (more reliable)<br>**Extrapolation**: Predicting outside the observed range (less reliable, can be misleading)",
        
        "context": "Predictions are estimates, not exact values. The further x is from the mean, the less precise the prediction typically becomes.",
        
        "image": {
          "src": "images/unit14/predictions_example.png",
          "alt": "Interpolation vs extrapolation",
          "caption": "Figure 14.7.19: Interpolation (safe) vs extrapolation (risky)."
        }
      },

      "worked_examples": [
        {
          "title": "Making Predictions",
          
          "image": {
            "src": "images/unit14/predictions_practice.png",
            "alt": "Practice making predictions",
            "caption": "Figure 14.7.20: Use the regression line to predict."
          },
          
          "problem": "Using the regression line $\\hat{y} = 0.9x + 1.3$ from our data (x from 1 to 5):<br>a) Predict y when x = 3.5<br>b) Predict y when x = 10<br>c) Which prediction is more reliable? Why?",
          
          "step_by_step": [
            {
              "step": "a) x = 3.5",
              "explanation": "Substitute into equation",
              "calculation": "$\\hat{y} = 0.9(3.5) + 1.3 = 3.15 + 1.3 = 4.45$"
            },
            {
              "step": "b) x = 10",
              "explanation": "Substitute into equation",
              "calculation": "$\\hat{y} = 0.9(10) + 1.3 = 9 + 1.3 = 10.3$"
            },
            {
              "step": "c) Compare reliability",
              "explanation": "x=3.5 is within our data range (1-5), x=10 is far outside",
              "calculation": "x=3.5 prediction (interpolation) is more reliable; x=10 is extrapolation"
            }
          ],
          
          "final_answer": "a) 4.45; b) 10.3; c) x=3.5 prediction is more reliable because it's interpolation within the data range.",
          "concept_applied": "Predictions are most reliable when x is within the range of observed data."
        }
      ],

      "image": {
        "src": "images/unit14/predictions_summary.png",
        "alt": "Summary of making predictions",
        "caption": "Figure 14.7.21: Predictions summary."
      }
    },

    {
      "section_title": "14.7.6 Residuals",
      
      "introduction": "Residuals are the differences between observed and predicted values. They help assess the fit of the line.",
      
      "introduction_image": {
        "src": "images/unit14/residuals_intro.png",
        "alt": "Residuals concept",
        "caption": "Figure 14.7.22: Residuals are vertical distances from points to the line."
      },
      
      "key_concept": {
        "definition": "A **residual** is the difference between the observed y-value and the predicted $\\hat{y}$-value: $$\\text{residual} = y - \\hat{y}$$<br><br>• Positive residual: Point is above the line (under-predicted)<br>• Negative residual: Point is below the line (over-predicted)<br>• Zero residual: Point lies exactly on the line<br><br>The sum of residuals in least squares regression is zero. Residual plots help check if a linear model is appropriate.",
        
        "context": "Analyzing residuals can reveal patterns that suggest a nonlinear relationship or the presence of outliers.",
        
        "image": {
          "src": "images/unit14/residuals_example.png",
          "alt": "Calculating residuals",
          "caption": "Figure 14.7.23: Residual = observed - predicted."
        }
      },

      "worked_examples": [
        {
          "title": "Calculating Residuals",
          
          "image": {
            "src": "images/unit14/residuals_practice.png",
            "alt": "Practice calculating residuals",
            "caption": "Figure 14.7.24: Calculate residuals for each point."
          },
          
          "problem": "Using the regression line $\\hat{y} = 0.9x + 1.3$ and the original data points (1,2), (2,3), (3,5), (4,4), (5,6), calculate the residual for each point.",
          
          "step_by_step": [
            {
              "step": "Calculate predicted values",
              "explanation": "For each x, find $\\hat{y}$",
              "calculation": "x=1: $\\hat{y}=0.9(1)+1.3=2.2$<br>x=2: $\\hat{y}=0.9(2)+1.3=3.1$<br>x=3: $\\hat{y}=0.9(3)+1.3=4.0$<br>x=4: $\\hat{y}=0.9(4)+1.3=4.9$<br>x=5: $\\hat{y}=0.9(5)+1.3=5.8$"
            },
            {
              "step": "Find residuals",
              "explanation": "residual = y - $\\hat{y}$",
              "calculation": "(1,2): $2-2.2 = -0.2$<br>(2,3): $3-3.1 = -0.1$<br>(3,5): $5-4.0 = 1.0$<br>(4,4): $4-4.9 = -0.9$<br>(5,6): $6-5.8 = 0.2$"
            },
            {
              "step": "Check sum",
              "explanation": "Sum of residuals should be approximately 0",
              "calculation": "$-0.2 + (-0.1) + 1.0 + (-0.9) + 0.2 = 0$"
            }
          ],
          
          "final_answer": "Residuals: -0.2, -0.1, 1.0, -0.9, 0.2",
          "concept_applied": "Residuals measure prediction error; sum of residuals = 0 in least squares."
        }
      ],

      "image": {
        "src": "images/unit14/residuals_summary.png",
        "alt": "Summary of residuals",
        "caption": "Figure 14.7.25: Residuals summary."
      }
    },

    {
      "section_title": "14.7.7 Coefficient of Determination (r²)",
      
      "introduction": "The coefficient of determination, r², tells us what proportion of the variation in y is explained by the linear relationship with x.",
      
      "introduction_image": {
        "src": "images/unit14/r_squared_intro.png",
        "alt": "Coefficient of determination concept",
        "caption": "Figure 14.7.26: r² measures how much variation is explained by the model."
      },
      
      "key_concept": {
        "definition": "The **coefficient of determination** $r^2$ is the square of the correlation coefficient. It represents the proportion of the variance in y that is predictable from x.<br><br>• $r^2 = 0.81$ means 81% of the variation in y is explained by the linear relationship with x<br>• $r^2$ ranges from 0 to 1<br>• Higher $r^2$ indicates a better fit of the line to the data<br><br>$r^2$ is also equal to: $$r^2 = \\frac{\\text{explained variation}}{\\text{total variation}}$$",
        
        "context": "If r² = 0.64, the model explains 64% of the variation; the other 36% is due to other factors or random variation.",
        
        "image": {
          "src": "images/unit14/r_squared_example.png",
          "alt": "r² interpretation",
          "caption": "Figure 14.7.27: r² = 0.81 means 81% of variation explained."
        }
      },

      "worked_examples": [
        {
          "title": "Interpreting r²",
          
          "image": {
            "src": "images/unit14/r_squared_practice.png",
            "alt": "Practice interpreting r²",
            "caption": "Figure 14.7.28: Interpret the given r² values."
          },
          
          "problem": "For each scenario, interpret what r² tells you:<br>a) Study time and test scores: r = 0.9, so r² = 0.81<br>b) Temperature and ice cream sales: r = 0.7, so r² = 0.49<br>c) Shoe size and IQ: r = 0.1, so r² = 0.01",
          
          "step_by_step": [
            {
              "step": "a) r² = 0.81",
              "explanation": "81% of variation in test scores explained by study time",
              "calculation": "Strong relationship, good predictive power"
            },
            {
              "step": "b) r² = 0.49",
              "explanation": "49% of variation in ice cream sales explained by temperature",
              "calculation": "Moderate relationship, some predictive power"
            },
            {
              "step": "c) r² = 0.01",
              "explanation": "Only 1% of variation in IQ explained by shoe size",
              "calculation": "Virtually no linear relationship"
            }
          ],
          
          "final_answer": "a) 81% explained, strong; b) 49% explained, moderate; c) 1% explained, very weak",
          "concept_applied": "r² measures proportion of variation explained by the linear model."
        }
      ],

      "image": {
        "src": "images/unit14/r_squared_summary.png",
        "alt": "Summary of coefficient of determination",
        "caption": "Figure 14.7.29: r² summary."
      }
    },

    {
      "section_title": "14.7.8 Common Errors with Line of Best Fit",
      
      "introduction": "Students often make predictable mistakes when working with lines of best fit.",
      
      "classifications": [
        {
          "type": "Extrapolation Without Warning",
          "value": "Making predictions far outside the data range without acknowledging the risk.",
          "characteristics": [
            "Assuming relationship continues unchanged",
            "Not mentioning extrapolation limitations"
          ],
          "behavior": "Unreliable or absurd predictions.",
          
          "image": {
            "src": "images/unit14/error_extrapolation.png",
            "alt": "Extrapolation can be misleading",
            "caption": "Figure 14.7.30: Error - extrapolating without caution."
          },
          
          "examples": [
            {
              "process": "Error: Using height at ages 2-18 to predict height at age 50 (growth stopped long before)",
              "explanation": "Correct: Acknowledge that extrapolation is unreliable"
            }
          ]
        },
        {
          "type": "Confusing r and r²",
          "value": "Interpreting r² as if it were r, or forgetting that r² is always positive.",
          "characteristics": [
            "Saying r² = 0.81 means weak correlation",
            "Forgetting that r² doesn't show direction"
          ],
          "behavior": "Misinterpretation of relationship strength.",
          
          "image": {
            "src": "images/unit14/error_r_squared.png",
            "alt": "r² doesn't show direction",
            "caption": "Figure 14.7.31: Error - confusing r and r²."
          },
          
          "examples": [
            {
              "process": "Error: r² = 0.81 means correlation is 0.81 (actually r could be ±0.9)",
              "explanation": "Correct: r² = 0.81 means |r| = 0.9, direction from scatter plot"
            }
          ]
        },
        {
          "type": "Forcing a Linear Model",
          "value": "Using a straight line when the relationship is clearly curved.",
          "characteristics": [
            "Ignoring pattern in residuals",
            "Not checking if linear model is appropriate"
          ],
          "behavior": "Poor fit and misleading predictions.",
          
          "image": {
            "src": "images/unit14/error_linear.png",
            "alt": "Don't force linear on curved data",
            "caption": "Figure 14.7.32: Error - forcing linear model on curved data."
          },
          
          "examples": [
            {
              "process": "Error: Fitting straight line to U-shaped data",
              "explanation": "Correct: Use nonlinear model or transform data"
            }
          ]
        }
      ],

      "worked_examples": [
        {
          "title": "Correcting Regression Errors",
          
          "image": {
            "src": "images/unit14/regression_errors_example.png",
            "alt": "Student's incorrect interpretation",
            "caption": "Figure 14.7.33: Find and correct the error."
          },
          
          "problem": "A student found r = 0.6 for a relationship between fertilizer amount and crop yield. They concluded that fertilizer causes 60% of the yield. What's wrong?",
          
          "step_by_step": [
            {
              "step": "Identify the error",
              "explanation": "Student confused correlation with causation and misinterpreted r",
              "calculation": "r = 0.6 indicates moderate positive correlation, not causation"
            },
            {
              "step": "Correct interpretation",
              "explanation": "r = 0.6 means moderate positive linear relationship",
              "calculation": "r² = 0.36 means 36% of yield variation explained by fertilizer"
            },
            {
              "step": "Causation issue",
              "explanation": "Correlation doesn't prove causation - other factors matter",
              "calculation": "Cannot claim fertilizer causes yield without controlled experiment"
            }
          ],
          
          "final_answer": "Two errors: (1) r measures correlation, not percentage explained (that's r²); (2) correlation ≠ causation. Correct: r=0.6 indicates moderate positive correlation; r²=0.36 means 36% of yield variation explained by fertilizer.",
          "concept_applied": "Distinguish between r, r², and causation in regression analysis."
        }
      ],

      "image": {
        "src": "images/unit14/regression_errors_summary.png",
        "alt": "Summary table of common regression errors",
        "caption": "Figure 14.7.34: Common errors summary."
      }
    },

    {
      "section_title": "14.7.9 Practice with Line of Best Fit",
      
      "introduction": "Apply your skills to find and interpret lines of best fit.",
      
      "worked_examples": [
        {
          "title": "Mixed Practice Set",
          
          "image": {
            "src": "images/unit14/regression_practice.png",
            "alt": "Multiple practice problems",
            "caption": "Figure 14.7.35: Practice problems."
          },
          
          "problem": "Data: Hours studied (x) and test score (y): (1, 55), (2, 60), (3, 65), (4, 68), (5, 72), (6, 75), (7, 78), (8, 82)<br><br>1) Find the least squares regression line<br>2) Calculate the correlation coefficient r<br>3) Find r² and interpret<br>4) Predict the score for a student who studies 4.5 hours<br>5) Calculate the residual for the point (5,72)<br>6) Is this a strong relationship? Explain.",
          
          "step_by_step": [
            {
              "step": "1) Calculate means",
              "explanation": "$\\bar{x} = \\frac{1+2+3+4+5+6+7+8}{8} = \\frac{36}{8} = 4.5$",
              "calculation": "$\\bar{y} = \\frac{55+60+65+68+72+75+78+82}{8} = \\frac{555}{8} = 69.375$"
            },
            {
              "step": "Calculate sums needed",
              "explanation": "Compute deviations and products",
              "calculation": "Will need computational assistance - doing by hand is lengthy<br>Using calculator or software gives:"
            },
            {
              "step": "Regression results",
              "explanation": "Using formulas, we get approximately:",
              "calculation": "$m \\approx 3.5$, $b \\approx 53.6$<br>$\\hat{y} = 3.5x + 53.6$"
            },
            {
              "step": "2) Correlation coefficient",
              "explanation": "Using formula",
              "calculation": "$r \\approx 0.98$ (very strong positive correlation)"
            },
            {
              "step": "3) r² interpretation",
              "explanation": "$r² = 0.96$",
              "calculation": "96% of variation in test scores explained by study hours"
            },
            {
              "step": "4) Predict at x=4.5",
              "explanation": "$\\hat{y} = 3.5(4.5) + 53.6$",
              "calculation": "$\\hat{y} = 15.75 + 53.6 = 69.35$"
            },
            {
              "step": "5) Residual at (5,72)",
              "explanation": "$\\hat{y} = 3.5(5) + 53.6 = 17.5 + 53.6 = 71.1$",
              "calculation": "residual = $72 - 71.1 = 0.9$"
            },
            {
              "step": "6) Strength",
              "explanation": "r = 0.98 indicates very strong positive correlation",
              "calculation": "Points closely follow the line"
            }
          ],
          
          "final_answer": "1) $\\hat{y} = 3.5x + 53.6$; 2) r = 0.98; 3) r² = 0.96, 96% explained; 4) 69.35; 5) 0.9; 6) Very strong positive relationship",
          "concept_applied": "Practice all aspects of regression analysis."
        }
      ],

      "image": {
        "src": "images/unit14/regression_practice_solutions.png",
        "alt": "Complete solutions to practice problems",
        "caption": "Figure 14.7.36: Practice solutions."
      }
    }
  ],

  "key_terms": [
    "Line of Best Fit",
    "Trend Line",
    "Regression Line",
    "Least Squares",
    "Slope",
    "Intercept",
    "Correlation Coefficient (r)",
    "Coefficient of Determination (r²)",
    "Residual",
    "Prediction",
    "Interpolation",
    "Extrapolation",
    "Median-Median Line",
    "Linear Model",
    "Explanatory Variable",
    "Response Variable"
  ],

  "summary": "The line of best fit summarizes the linear relationship between two variables. It can be estimated by eye, found using the median-median method (resistant to outliers), or calculated precisely using least squares regression. The least squares line $\\hat{y} = mx + b$ minimizes the sum of squared residuals, where slope $m = \\frac{\\sum(x-\\bar{x})(y-\\bar{y})}{\\sum(x-\\bar{x})^2}$ and intercept $b = \\bar{y} - m\\bar{x}$. The correlation coefficient $r$ measures strength and direction (-1 to +1), with $|r| > 0.8$ indicating strong correlation. $r^2$ tells the proportion of variation in y explained by x. The line can be used for predictions, but extrapolation (predicting outside the data range) is risky. Residuals ($y - \\hat{y}$) help assess fit and should show no pattern. Common errors include misinterpreting r vs r², assuming causation from correlation, and forcing linear models on curved data. Mastery of these concepts is essential for data analysis and statistical modeling.",

  "review_questions_image": {
    "src": "images/unit14/line_of_best_fit_summary.png",
    "alt": "Comprehensive summary: estimation methods, least squares formulas, correlation coefficient, residuals, predictions, r², common errors",
    "caption": "Figure 14.7.37: Line of best fit summary."
  }
}
