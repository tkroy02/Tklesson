{
  "expanded_description": "Every statistic we calculate from a sample — a mean, a proportion, a percentage — is our best single guess at an unknown population parameter. But a single guess is fragile. What we really want to know is: given what we observed, what is a reasonable range of values for the truth? Confidence intervals answer exactly that question. They are one of the most powerful and most misunderstood tools in all of statistics, and they appear everywhere: in medical research, political polling, product testing, and public policy.",

  "core_concept": {
    "principle": "A confidence interval gives a range of plausible values for an unknown population parameter, based on data from a sample. Instead of saying 'the parameter is exactly $\\hat{p}$,' we say 'we are confident the parameter falls somewhere between $L$ and $U$.'",
    "explanation": "Here is the fundamental problem: we take a sample, calculate a statistic like $\\bar{x}$ or $\\hat{p}$, and use it to estimate a population parameter like $\\mu$ or $p$. But every sample is different. If we took a second sample, we'd get a slightly different $\\bar{x}$. A third sample: yet another value. This variation is called sampling variability, and it means our single-number estimate ($\\bar{x}$) almost certainly misses the true parameter by at least a little. A confidence interval acknowledges this uncertainty honestly — instead of pretending our sample statistic is exactly right, we build a range around it that is wide enough to capture the true parameter with a specified level of confidence. The width of that range and the confidence level both depend on how much data we have and how much variability exists in the population."
  },

  "sections": [
    {
      "section_title": "The Problem with Point Estimates",
      "introduction": "Before we can appreciate confidence intervals, we need to understand why a single number estimate — called a point estimate — is insufficient on its own. This section explains the problem that confidence intervals are designed to solve.",

      "key_concept": {
        "definition": "A point estimate is a single value calculated from sample data used to estimate a population parameter. For example, the sample mean $\\bar{x}$ is a point estimate for the population mean $\\mu$, and the sample proportion $\\hat{p}$ is a point estimate for the population proportion $p$. Point estimates are useful but incomplete — they give no information about how close they are likely to be to the truth.",
        "context": "Think of it this way. A friend asks: 'How long will it take to drive from here to Chicago?' You could say '4 hours and 23 minutes' (a point estimate — sounds precise, but almost certainly wrong). Or you could say 'between 4 and 5 hours depending on traffic' (an interval — less precise, but far more honest and useful). The interval communicates both your best estimate AND your uncertainty. Confidence intervals do exactly this for population parameters."
      },

      "classifications": [
        {
          "type": "Point Estimate vs. Interval Estimate",
          "value": "Understanding this distinction is the conceptual foundation of the entire section",
          "characteristics": [
            "Point estimate: a single number used to estimate a parameter — $\\bar{x}$ estimates $\\mu$; $\\hat{p}$ estimates $p$",
            "Interval estimate: a range of values believed to contain the parameter — more informative than a point estimate",
            "A point estimate has zero width — it's a single value with no built-in acknowledgment of uncertainty",
            "An interval estimate has width — the wider it is, the more uncertainty it reflects",
            "Point estimates are almost never exactly equal to the parameter — they are always off by some amount",
            "We can never know how far off a point estimate is (because we don't know the parameter) — this is why we need intervals"
          ],
          "behavior": "Every time you compute $\\bar{x}$ or $\\hat{p}$ from a sample, you have a point estimate. It's your best single guess, and it's valuable — but it's incomplete without some measure of uncertainty. A confidence interval upgrades the point estimate into a more honest statement: 'I believe the true value is somewhere in this range.' The tradeoff is that intervals require more information (specifically, the standard deviation and sample size) and produce a range rather than a clean single number.",
          "examples": [
            {
              "process": "Point Estimate for a Mean",
              "explanation": "A researcher samples 50 Algebra 2 students and finds they average $\\bar{x} = 6.8$ hours of sleep. This is a point estimate of $\\mu$ (the true mean sleep for all Algebra 2 students). It's precise-sounding but doesn't tell us: Could $\\mu$ be 6.5? Could it be 7.1? We have no idea how uncertain this estimate is without more information."
            },
            {
              "process": "Point Estimate for a Proportion",
              "explanation": "A poll of 600 voters finds $\\hat{p} = 0.54$ (54%) support a ballot measure. This is a point estimate for $p$, the true proportion of all voters who support it. Does this mean the measure will pass? Not necessarily — $p$ could be 0.51 or 0.49, and we'd need to know the uncertainty in $\\hat{p}$ to judge."
            },
            {
              "process": "Why the Uncertainty Matters",
              "explanation": "Two polls both report $\\hat{p} = 0.54$ support for a candidate. Poll A surveyed $n = 30$ people. Poll B surveyed $n = 2{,}000$ people. Both give the same point estimate. But Poll A's estimate could easily be off by $\\pm 18\\%$ (the true value might be anywhere from 36% to 72%). Poll B's estimate is much more reliable — off by at most $\\pm 2\\%$. The point estimate doesn't communicate this difference at all. Confidence intervals do."
            }
          ]
        },
        {
          "type": "Sampling Variability — Why Estimates Differ",
          "value": "The root cause of all uncertainty in statistics — must be understood before confidence intervals make sense",
          "characteristics": [
            "Every sample drawn from the same population produces a (slightly) different statistic",
            "This sample-to-sample variation is called sampling variability (or sampling error)",
            "Sampling variability is not a mistake — it is an unavoidable consequence of using a sample instead of a census",
            "The amount of variability depends on: (1) sample size $n$ — larger $n$ means less variability; (2) population spread $\\sigma$ — more spread means more variability",
            "Sampling variability is quantified by the standard error: $SE = \\frac{\\sigma}{\\sqrt{n}}$ for means",
            "The standard error tells us how much $\\bar{x}$ typically varies from one sample to the next"
          ],
          "behavior": "Imagine you could take thousands of different samples of size $n$ from the same population and compute $\\bar{x}$ for each. You'd get thousands of slightly different values — a whole distribution of sample means. This distribution has its own mean (equal to $\\mu$) and its own standard deviation (the standard error $SE = \\sigma/\\sqrt{n}$). The Central Limit Theorem (previewed in Section 10.2) tells us this distribution is approximately normal for large $n$. This normal distribution of sample means is the mathematical backbone of confidence intervals.",
          "examples": [
            {
              "process": "Visualizing Sampling Variability",
              "explanation": "Suppose the true mean height of all students at a school is $\\mu = 65$ inches. Take a random sample of $n = 30$ students — compute $\\bar{x}$. Maybe you get 64.7. Take another sample of 30 — maybe 65.4. Take a third — maybe 64.9. Each sample gives a different $\\bar{x}$. None of them equal 65 exactly, but they cluster around 65. The spread of these $\\bar{x}$ values is the sampling variability, measured by $SE = \\sigma/\\sqrt{n}$."
            },
            {
              "process": "Standard Error Calculation",
              "explanation": "A population has $\\sigma = 10$. With $n = 25$: $SE = 10/\\sqrt{25} = 10/5 = 2$. With $n = 100$: $SE = 10/\\sqrt{100} = 10/10 = 1$. With $n = 400$: $SE = 10/\\sqrt{400} = 10/20 = 0.5$. As sample size quadruples, the standard error halves. This is why large samples are more reliable — sample means vary less from the true parameter."
            }
          ]
        }
      ]
    },

    {
      "section_title": "What Is a Confidence Interval?",
      "introduction": "Now that we understand why point estimates are uncertain, we can build the solution: a confidence interval. This section introduces the structure, formula, and correct interpretation of confidence intervals — including one of the most commonly tested misconceptions in all of statistics.",

      "key_concept": {
        "definition": "A confidence interval (CI) is an interval estimate of a population parameter, constructed from sample data, that contains the true parameter value with a specified probability called the confidence level. A $C\\%$ confidence interval is written as: $\\text{point estimate} \\pm \\text{margin of error}$, or equivalently as $(\\text{lower bound},\\ \\text{upper bound})$.",
        "context": "The confidence level (90%, 95%, 99% are the most common) tells you: if we repeated the sampling process many times and built a confidence interval each time, $C\\%$ of those intervals would contain the true parameter. This is a subtle but critical statement — we'll unpack it carefully in this section because it is one of the most frequently misunderstood concepts in introductory statistics."
      },

      "classifications": [
        {
          "type": "Anatomy of a Confidence Interval",
          "value": "Every confidence interval has these three components — identify each one for every problem",
          "characteristics": [
            "Point estimate: the center of the interval — your best single guess at the parameter ($\\bar{x}$ or $\\hat{p}$)",
            "Margin of error (ME): the amount added and subtracted from the point estimate to create the interval width",
            "Confidence level $C$: the percentage of intervals that would capture the true parameter if the process were repeated many times (typically 90%, 95%, or 99%)",
            "Lower bound: point estimate $-$ margin of error",
            "Upper bound: point estimate $+$ margin of error",
            "Full interval notation: $(\\bar{x} - ME,\\ \\bar{x} + ME)$ or $\\bar{x} \\pm ME$",
            "The margin of error is always HALF the total width of the interval"
          ],
          "behavior": "The structure is always the same: start at the point estimate (center), go left by the margin of error (lower bound), go right by the margin of error (upper bound). The resulting interval is symmetric around the point estimate. A wider interval reflects more uncertainty (either small $n$, high variability, or a higher confidence level). A narrower interval reflects more precision (large $n$, low variability, or a lower confidence level).",
          "examples": [
            {
              "process": "Reading a Confidence Interval",
              "explanation": "A 95% CI for the mean sleep hours of Algebra 2 students is reported as $(6.2, 7.4)$ hours. Point estimate: $\\bar{x} = (6.2 + 7.4)/2 = 6.8$ hours (center of interval). Margin of error: $(7.4 - 6.2)/2 = 0.6$ hours. We are 95% confident the true mean sleep hours $\\mu$ is between 6.2 and 7.4 hours."
            },
            {
              "process": "Building a CI from Components",
              "explanation": "A survey finds $\\hat{p} = 0.62$ support for a policy. The margin of error is 0.04. The 95% CI is: $0.62 \\pm 0.04$, which gives the interval $(0.58,\\ 0.66)$. We are 95% confident the true proportion of supporters $p$ is between 58% and 66%."
            },
            {
              "process": "Extracting Components from an Interval",
              "explanation": "A 99% CI for average daily screen time is reported as $(5.1,\\ 6.9)$ hours. Point estimate: $(5.1 + 6.9)/2 = 6.0$ hours. Margin of error: $(6.9 - 5.1)/2 = 0.9$ hours. Total interval width: $6.9 - 5.1 = 1.8$ hours. Note: ME = width$/2$."
            }
          ]
        },
        {
          "type": "The Confidence Level — What It Actually Means",
          "value": "The most nuanced concept in this section — and the most frequently misinterpreted",
          "characteristics": [
            "The confidence level (e.g., 95%) is a statement about the METHOD, not about any single interval",
            "Correct interpretation: if we repeated the sampling process many times and constructed a CI each time, $C\\%$ of those intervals would contain the true parameter",
            "A 95% CI does NOT mean: 'there is a 95% chance the true parameter is in this interval'",
            "Once an interval is constructed, the parameter either IS or IS NOT in it — probability is no longer involved",
            "Higher confidence level → wider interval (more certain, but less precise)",
            "Lower confidence level → narrower interval (more precise, but less certain)",
            "The 95% confidence level is the most commonly used in practice — a good balance of confidence and precision"
          ],
          "behavior": "The confidence level is attached to the long-run performance of the method, not to any individual interval. Think of it like a basketball player who makes 95% of free throws. Before any particular free throw, you'd say there's a 95% chance they'll make it. But once the ball leaves their hands — either it goes in or it doesn't. That specific shot doesn't have a 95% probability anymore. Similarly: before we collect data, a 95% CI procedure will succeed 95% of the time. After we calculate a specific interval, that specific interval either contains $\\mu$ or it doesn't.",
          "examples": [
            {
              "process": "Correct Interpretation (Memorize This Phrasing)",
              "explanation": "A 95% CI for mean GPA is $(3.1,\\ 3.5)$. CORRECT: 'We are 95% confident that the true mean GPA $\\mu$ is between 3.1 and 3.5.' CORRECT: 'This interval was constructed using a method that captures the true parameter 95% of the time.' WRONG: 'There is a 95% probability that $\\mu$ is between 3.1 and 3.5.' (The parameter is fixed — it doesn't have a probability distribution once the interval is built.)"
            },
            {
              "process": "The Long-Run Picture",
              "explanation": "Imagine taking 100 different random samples from the same population and building a 95% CI from each. Approximately 95 of those 100 intervals will contain the true parameter $\\mu$. About 5 will miss — by random chance, their sample was unusually extreme. We never know which intervals are the lucky 95 and which are the unlucky 5. We only know that the method succeeds 95% of the time."
            },
            {
              "process": "Why Higher Confidence Requires Wider Intervals",
              "explanation": "To be 99% confident instead of 95% confident, you need a wider net. Analogy: if you want to be 95% sure a fish is in your net, you cast a medium-sized net. To be 99% sure, you need a bigger net. The 'net' is your confidence interval. More confidence = wider interval = less precision about exactly where the parameter is. There is always a tradeoff between confidence and precision."
            }
          ]
        }
      ]
    },

    {
      "section_title": "The Critical Value — Connecting Confidence Levels to the Normal Curve",
      "introduction": "The confidence level determines how wide the interval needs to be. Translating a confidence level (like 95%) into the actual number of standard errors to add and subtract requires a critical value, written $z^*$. This section shows where critical values come from and how to use them.",

      "key_concept": {
        "definition": "The critical value $z^*$ (read 'z-star') is the number of standard deviations from the mean that captures the middle $C\\%$ of the standard normal distribution. It is the multiplier that converts the standard error into the margin of error. For a $C\\%$ confidence interval: $ME = z^* \\cdot SE$.",
        "context": "You already know from the Empirical Rule (Section 10.2) that approximately 95% of data falls within $\\pm 2$ standard deviations of the mean in a normal distribution. The critical value for 95% confidence is the precise version of this: $z^* = 1.96$ (not exactly 2, but close). The three critical values you must memorize for this course are $z^* = 1.645$ for 90%, $z^* = 1.96$ for 95%, and $z^* = 2.576$ for 99% confidence."
      },

      "classifications": [
        {
          "type": "The Three Standard Critical Values",
          "value": "Memorize these — they appear in every confidence interval and margin of error problem",
          "characteristics": [
            "90% confidence level: $z^* = 1.645$ — captures the middle 90% of the standard normal distribution",
            "95% confidence level: $z^* = 1.96$ — captures the middle 95% of the standard normal distribution",
            "99% confidence level: $z^* = 2.576$ — captures the middle 99% of the standard normal distribution",
            "Higher confidence level → larger $z^*$ → wider margin of error → wider interval",
            "$z^* = 1.96$ is the most commonly tested value — it corresponds to the nearly-2 standard deviations from Section 10.2",
            "In each tail beyond $\\pm z^*$: for 95%, each tail has $(100\\% - 95\\%)/2 = 2.5\\%$ of the area",
            "These values come from a z-table or the standard normal distribution — the same tool from Section 10.3"
          ],
          "behavior": "To find $z^*$: identify your confidence level $C$. The tails beyond $\\pm z^*$ together contain $(100\\% - C\\%)$, so each individual tail contains $(100\\% - C\\%)/2$. Look up in a z-table the z-score that has that area to its LEFT — that's $z^*$. In practice, the three values above are standard and should be memorized. For a 95% CI: each tail has 2.5%, so you look up the z-score with 97.5% to its left, which is $z^* = 1.96$.",
          "examples": [
            {
              "process": "Deriving $z^* = 1.96$ from the 95% Level",
              "explanation": "95% confidence: middle 95% is captured, leaving 5% in both tails combined. Each tail: $5\\%/2 = 2.5\\%$. We need the z-score with $100\\% - 2.5\\% = 97.5\\%$ of the area to its LEFT in the standard normal distribution. From the z-table: $z = 1.96$. So $z^* = 1.96$ for 95% confidence."
            },
            {
              "process": "Deriving $z^* = 1.645$ from the 90% Level",
              "explanation": "90% confidence: middle 90% captured, 10% in tails, 5% in each tail. Need z-score with 95% area to the left. From the z-table: $z \\approx 1.645$. So $z^* = 1.645$ for 90% confidence."
            },
            {
              "process": "Connection to Section 10.2",
              "explanation": "In Section 10.2, we used $\\mu \\pm 2\\sigma$ to capture 95% of data. The precise version is $\\mu \\pm 1.96\\sigma$. The Empirical Rule uses 2 as an approximation; confidence intervals use the exact value 1.96. You'll see both — know that $z^* \\approx 2$ and $z^* = 1.96$ are both referring to 95% confidence."
            }
          ]
        },
        {
          "type": "Standard Error — The Building Block of Every Confidence Interval",
          "value": "Standard error quantifies sampling variability and determines how wide the margin of error will be",
          "characteristics": [
            "Standard error for a mean (when $\\sigma$ is known): $SE_{\\bar{x}} = \\dfrac{\\sigma}{\\sqrt{n}}$",
            "Standard error for a proportion: $SE_{\\hat{p}} = \\sqrt{\\dfrac{\\hat{p}(1-\\hat{p})}{n}}$",
            "Standard error decreases as $n$ increases — larger samples → smaller SE → narrower intervals",
            "Standard error increases as $\\sigma$ or variability increases — more spread → wider intervals",
            "Standard error is NOT the same as standard deviation: $s$ describes spread within the sample; $SE$ describes variability of the statistic across samples",
            "Every margin of error formula has the form: $ME = z^* \\cdot SE$"
          ],
          "behavior": "The standard error is the price of sampling: because we only have a sample, our statistic ($\\bar{x}$ or $\\hat{p}$) varies from the truth. The SE measures how much. A small SE means our statistic is tightly clustered around the true parameter — we can be confident in our estimate. A large SE means our statistic could be far from the truth in either direction — we need a wider interval to be confident. Reducing SE requires increasing $n$ (the only thing we can control, since $\\sigma$ is a property of the population).",
          "examples": [
            {
              "process": "Standard Error for a Mean",
              "explanation": "A school district knows from prior years that student GPA has $\\sigma = 0.5$. They sample $n = 100$ students. $SE = 0.5/\\sqrt{100} = 0.5/10 = 0.05$ GPA points. The sample mean $\\bar{x}$ typically varies from $\\mu$ by only about 0.05 points — very precise."
            },
            {
              "process": "Standard Error for a Proportion",
              "explanation": "A poll finds $\\hat{p} = 0.60$ support for a policy among $n = 400$ voters. $SE = \\sqrt{0.60 \\times 0.40 / 400} = \\sqrt{0.24/400} = \\sqrt{0.0006} \\approx 0.0245$. The sample proportion typically varies from the true proportion by about 2.45 percentage points."
            },
            {
              "process": "Effect of Changing $n$ on SE",
              "explanation": "A population proportion is estimated with $\\hat{p} = 0.50$. Compare SEs: $n = 100$: $SE = \\sqrt{0.50 \\times 0.50/100} = \\sqrt{0.0025} = 0.05$. $n = 400$: $SE = \\sqrt{0.25/400} = 0.025$. $n = 1600$: $SE = \\sqrt{0.25/1600} = 0.0125$. Every time $n$ quadruples, $SE$ halves. This $\\frac{1}{\\sqrt{n}}$ relationship is fundamental — doubling precision requires quadrupling sample size."
            }
          ]
        }
      ]
    },

    {
      "section_title": "Confidence Intervals for a Proportion",
      "introduction": "The most common confidence interval in everyday life estimates a population proportion $p$ — the fraction of a population with some characteristic. Election polls, approval ratings, product defect rates, and survey percentages are all estimates of proportions. This section builds the complete formula and walks through it step by step.",

      "key_concept": {
        "definition": "A confidence interval for a population proportion $p$ is: $\\hat{p} \\pm z^* \\cdot \\sqrt{\\dfrac{\\hat{p}(1-\\hat{p})}{n}}$, which gives the interval $\\left(\\hat{p} - z^* \\cdot SE,\\ \\hat{p} + z^* \\cdot SE\\right)$. Here $\\hat{p}$ is the sample proportion, $n$ is the sample size, and $z^*$ is the critical value for the desired confidence level.",
        "context": "This formula applies when: (1) the sample was collected using random sampling (SRS or equivalent), and (2) the sample is large enough — we need at least 10 successes and 10 failures in the sample (the 'success-failure condition'): $n\\hat{p} \\geq 10$ and $n(1-\\hat{p}) \\geq 10$. When both conditions are met, the sampling distribution of $\\hat{p}$ is approximately normal, which is what justifies using a z-score as the critical value."
      },

      "classifications": [
        {
          "type": "One-Proportion Z-Interval — Full Formula",
          "value": "Use when estimating a population proportion from sample data",
          "characteristics": [
            "Formula: $\\hat{p} \\pm z^* \\cdot \\sqrt{\\dfrac{\\hat{p}(1-\\hat{p})}{n}}$",
            "Point estimate (center): $\\hat{p}$ — the sample proportion",
            "Standard error: $SE = \\sqrt{\\hat{p}(1-\\hat{p})/n}$",
            "Margin of error: $ME = z^* \\cdot \\sqrt{\\hat{p}(1-\\hat{p})/n}$",
            "Conditions: (1) Random sample; (2) $n\\hat{p} \\geq 10$ AND $n(1-\\hat{p}) \\geq 10$ (success-failure condition)",
            "If $\\hat{p} = 0.5$, the SE is at its maximum — most uncertainty when a population is evenly split",
            "The interval is symmetric around $\\hat{p}$"
          ],
          "behavior": "Step 1: Identify $\\hat{p}$, $n$, and the confidence level. Step 2: Verify conditions (random sample; success-failure). Step 3: Find $z^*$ (1.645 for 90%, 1.96 for 95%, 2.576 for 99%). Step 4: Calculate $SE = \\sqrt{\\hat{p}(1-\\hat{p})/n}$. Step 5: Calculate $ME = z^* \\times SE$. Step 6: Build the interval: $\\hat{p} \\pm ME$. Step 7: Interpret in context using the correct phrasing.",
          "examples": [
            {
              "process": "Quick Check: Success-Failure Condition",
              "explanation": "A sample of $n = 80$ students, $\\hat{p} = 0.35$ have a part-time job. Check: $n\\hat{p} = 80 \\times 0.35 = 28 \\geq 10$ ✓ and $n(1-\\hat{p}) = 80 \\times 0.65 = 52 \\geq 10$ ✓. Condition is met — normal approximation is valid. If either count were below 10, we could not use this formula."
            },
            {
              "process": "When the Success-Failure Condition Fails",
              "explanation": "A sample of $n = 40$ patients, $\\hat{p} = 0.05$ experienced a side effect. Check: $n\\hat{p} = 40 \\times 0.05 = 2 < 10$ ✗. Condition FAILS. The sampling distribution of $\\hat{p}$ is not approximately normal here (too few successes), so the z-interval formula is not appropriate. A different method (beyond Algebra 2 scope) would be needed."
            }
          ]
        }
      ],

      "worked_examples": [
        {
          "title": "Election Poll — Confidence Interval for a Proportion",
          "problem": "A polling organization surveys a random sample of $n = 500$ registered voters. 285 say they will vote for Candidate A. Construct a 95% confidence interval for the true proportion of all voters who support Candidate A. Interpret your result in context.",
          "step_by_step": [
            {
              "step": "Identify the Given Information",
              "explanation": "Read the problem and extract all numbers before doing any calculation.",
              "calculation": "$n = 500$ voters surveyed. 285 support Candidate A. Confidence level: 95%."
            },
            {
              "step": "Calculate the Sample Proportion $\\hat{p}$",
              "explanation": "$\\hat{p}$ = (number of successes) $\\div$ (sample size). Here, a 'success' is a voter who supports Candidate A.",
              "calculation": "$\\hat{p} = 285/500 = 0.57$ (57% of the sample supports Candidate A)"
            },
            {
              "step": "Check the Conditions",
              "explanation": "Verify: (1) random sample, and (2) success-failure condition.",
              "calculation": "(1) The problem states 'random sample' ✓. (2) $n\\hat{p} = 500 \\times 0.57 = 285 \\geq 10$ ✓ and $n(1-\\hat{p}) = 500 \\times 0.43 = 215 \\geq 10$ ✓. Conditions met."
            },
            {
              "step": "Find the Critical Value $z^*$",
              "explanation": "For 95% confidence, the critical value is standard.",
              "calculation": "$z^* = 1.96$ for 95% confidence."
            },
            {
              "step": "Calculate the Standard Error",
              "explanation": "Plug $\\hat{p} = 0.57$ and $n = 500$ into the SE formula.",
              "calculation": "$SE = \\sqrt{\\dfrac{0.57 \\times 0.43}{500}} = \\sqrt{\\dfrac{0.2451}{500}} = \\sqrt{0.0004902} \\approx 0.02214$"
            },
            {
              "step": "Calculate the Margin of Error",
              "explanation": "Multiply $z^*$ by the standard error.",
              "calculation": "$ME = 1.96 \\times 0.02214 \\approx 0.0434 \\approx 0.043$"
            },
            {
              "step": "Build the Confidence Interval",
              "explanation": "Add and subtract the margin of error from the point estimate.",
              "calculation": "Lower bound: $0.57 - 0.043 = 0.527$. Upper bound: $0.57 + 0.043 = 0.613$. CI: $(0.527,\\ 0.613)$, or equivalently $0.57 \\pm 0.043$."
            },
            {
              "step": "Interpret in Context",
              "explanation": "Write a sentence that connects the numbers to the real situation. Use the standard phrasing: 'We are [C]% confident that the true [parameter] is between [L] and [U].'",
              "calculation": "We are 95% confident that the true proportion of all registered voters who support Candidate A is between 52.7% and 61.3%."
            },
            {
              "step": "Answer the Practical Question",
              "explanation": "Since the poll is about whether a candidate will win, we check: does the interval contain 50%? If the entire interval is above 50%, the candidate is likely winning.",
              "calculation": "The entire interval $(52.7\\%,\\ 61.3\\%)$ is above 50%. This suggests Candidate A is likely ahead, but the margin could be as small as 2.7 percentage points."
            }
          ],
          "final_answer": "95% CI: $(0.527,\\ 0.613)$. We are 95% confident the true proportion of voters supporting Candidate A is between 52.7% and 61.3%. Since the entire interval exceeds 50%, the data provides evidence that a majority of voters support Candidate A.",
          "concept_applied": "The confidence interval tells us not just our best estimate (57%), but the full range of plausible values for the true proportion. A point estimate alone would not reveal whether the lead is statistically meaningful."
        }
      ]
    },

    {
      "section_title": "Confidence Intervals for a Mean",
      "introduction": "When the variable of interest is quantitative (test scores, temperatures, weights, incomes), we estimate the population mean $\\mu$ rather than a proportion. The structure of the interval is identical — point estimate $\\pm$ margin of error — but the formula for the standard error and the critical value differ based on whether we know the population standard deviation $\\sigma$.",

      "key_concept": {
        "definition": "A confidence interval for a population mean $\\mu$ (when $\\sigma$ is known) is: $\\bar{x} \\pm z^* \\cdot \\dfrac{\\sigma}{\\sqrt{n}}$. When $\\sigma$ is unknown (the more common real-world situation), we use the sample standard deviation $s$ and a t-distribution instead of the standard normal. In Algebra 2, we focus primarily on the case where $\\sigma$ is given or where $n$ is large enough that $s \\approx \\sigma$.",
        "context": "In practice, we almost never know the population standard deviation $\\sigma$ exactly. When $n$ is large (typically $n \\geq 30$), $s$ is a good enough estimate of $\\sigma$ and the z-interval formula still works well. When $n$ is small and $\\sigma$ is unknown, a t-distribution should be used — but the logic and interpretation are identical. We will focus on the large-sample case and cases where $\\sigma$ is provided."
      },

      "classifications": [
        {
          "type": "Z-Interval for a Mean (Large Sample or Known $\\sigma$)",
          "value": "Use when estimating a population mean with a large sample ($n \\geq 30$) or when $\\sigma$ is known",
          "characteristics": [
            "Formula: $\\bar{x} \\pm z^* \\cdot \\dfrac{\\sigma}{\\sqrt{n}}$",
            "Point estimate (center): $\\bar{x}$ — the sample mean",
            "Standard error: $SE = \\sigma/\\sqrt{n}$ (or $s/\\sqrt{n}$ when $\\sigma$ is unknown but $n \\geq 30$)",
            "Margin of error: $ME = z^* \\cdot \\sigma/\\sqrt{n}$",
            "Conditions: (1) Random sample; (2) population is normal OR $n \\geq 30$ (Central Limit Theorem applies)",
            "If $\\sigma$ is unknown and $n < 30$, a t-interval should be used (beyond Algebra 2 scope)"
          ],
          "behavior": "The steps are exactly the same as for a proportion interval: identify parameters, check conditions, find $z^*$, compute $SE$, compute $ME$, build the interval, interpret in context. The only difference is the SE formula: $\\sigma/\\sqrt{n}$ instead of $\\sqrt{\\hat{p}(1-\\hat{p})/n}$.",
          "examples": [
            {
              "process": "Comparing SE for Means vs. Proportions",
              "explanation": "Mean SE: $\\sigma/\\sqrt{n}$ — depends on the population spread $\\sigma$ and sample size $n$. Proportion SE: $\\sqrt{\\hat{p}(1-\\hat{p})/n}$ — depends on how evenly split the proportion is and sample size $n$. Both decrease as $n$ increases. Both produce a margin of error by multiplying by $z^*$. Same structure, different formulas for the spread."
            }
          ]
        }
      ],

      "worked_examples": [
        {
          "title": "Mean Study Hours — Confidence Interval for a Mean",
          "problem": "A researcher wants to estimate the average number of hours per week high school students spend studying. She surveys a random sample of $n = 64$ students and finds $\\bar{x} = 12.4$ hours with a sample standard deviation of $s = 4.8$ hours. Construct a 95% confidence interval for the true mean study hours. Interpret your result.",
          "step_by_step": [
            {
              "step": "Identify the Given Information",
              "explanation": "Extract all values from the problem.",
              "calculation": "$n = 64$, $\\bar{x} = 12.4$ hours, $s = 4.8$ hours. Confidence level: 95%. Note: $\\sigma$ is not given — we'll use $s$ since $n = 64 \\geq 30$."
            },
            {
              "step": "Check the Conditions",
              "explanation": "Verify random sampling and large-sample condition.",
              "calculation": "(1) 'Random sample' stated ✓. (2) $n = 64 \\geq 30$ ✓ — the Central Limit Theorem guarantees the sampling distribution of $\\bar{x}$ is approximately normal. Conditions met."
            },
            {
              "step": "Find the Critical Value $z^*$",
              "explanation": "95% confidence → standard critical value.",
              "calculation": "$z^* = 1.96$"
            },
            {
              "step": "Calculate the Standard Error",
              "explanation": "Use $s$ in place of $\\sigma$ since $\\sigma$ is unknown but $n \\geq 30$.",
              "calculation": "$SE = \\dfrac{s}{\\sqrt{n}} = \\dfrac{4.8}{\\sqrt{64}} = \\dfrac{4.8}{8} = 0.6$ hours"
            },
            {
              "step": "Calculate the Margin of Error",
              "explanation": "Multiply $z^*$ by $SE$.",
              "calculation": "$ME = z^* \\times SE = 1.96 \\times 0.6 = 1.176 \\approx 1.18$ hours"
            },
            {
              "step": "Build the Confidence Interval",
              "explanation": "Apply $\\bar{x} \\pm ME$.",
              "calculation": "Lower bound: $12.4 - 1.18 = 11.22$ hours. Upper bound: $12.4 + 1.18 = 13.58$ hours. CI: $(11.22,\\ 13.58)$ hours."
            },
            {
              "step": "Interpret in Context",
              "explanation": "Write a complete sentence connecting numbers to the real-world situation.",
              "calculation": "We are 95% confident that the true mean number of weekly study hours for high school students is between 11.22 and 13.58 hours."
            }
          ],
          "final_answer": "95% CI: $(11.22,\\ 13.58)$ hours. We are 95% confident that the true mean weekly study time for high school students is between 11.22 and 13.58 hours.",
          "concept_applied": "When $\\sigma$ is unknown but $n \\geq 30$, substitute $s$ for $\\sigma$ and proceed with the z-interval. The logic and interpretation are identical."
        },
        {
          "title": "Coffee Temperature — Effect of Confidence Level on Interval Width",
          "problem": "A café chain wants to estimate the mean temperature at which their coffee is served. From historical records, $\\sigma = 4°F$. A quality control inspector measures $n = 36$ cups and finds $\\bar{x} = 162°F$. (a) Construct a 90% CI. (b) Construct a 95% CI. (c) Construct a 99% CI. (d) What do you notice about the relationship between confidence level and interval width?",
          "step_by_step": [
            {
              "step": "Identify the Given Information",
              "explanation": "Consistent across all three parts.",
              "calculation": "$n = 36$, $\\bar{x} = 162°F$, $\\sigma = 4°F$ (known from records)."
            },
            {
              "step": "Calculate the Standard Error (Same for All Three)",
              "explanation": "$\\sigma$ is known, so use the exact formula.",
              "calculation": "$SE = \\dfrac{\\sigma}{\\sqrt{n}} = \\dfrac{4}{\\sqrt{36}} = \\dfrac{4}{6} \\approx 0.667°F$"
            },
            {
              "step": "Part (a): 90% Confidence Interval",
              "explanation": "Use $z^* = 1.645$ for 90% confidence.",
              "calculation": "$ME_{90} = 1.645 \\times 0.667 \\approx 1.097 \\approx 1.10°F$. CI: $(162 - 1.10,\\ 162 + 1.10) = (160.90°F,\\ 163.10°F)$. Width: $2.20°F$."
            },
            {
              "step": "Part (b): 95% Confidence Interval",
              "explanation": "Use $z^* = 1.96$ for 95% confidence.",
              "calculation": "$ME_{95} = 1.96 \\times 0.667 \\approx 1.307 \\approx 1.31°F$. CI: $(162 - 1.31,\\ 162 + 1.31) = (160.69°F,\\ 163.31°F)$. Width: $2.62°F$."
            },
            {
              "step": "Part (c): 99% Confidence Interval",
              "explanation": "Use $z^* = 2.576$ for 99% confidence.",
              "calculation": "$ME_{99} = 2.576 \\times 0.667 \\approx 1.718 \\approx 1.72°F$. CI: $(162 - 1.72,\\ 162 + 1.72) = (160.28°F,\\ 163.72°F)$. Width: $3.44°F$."
            },
            {
              "step": "Part (d): Analyze the Pattern",
              "explanation": "Compare all three intervals directly.",
              "calculation": "90% CI: $(160.90,\\ 163.10)$ — width $2.20°F$. 95% CI: $(160.69,\\ 163.31)$ — width $2.62°F$. 99% CI: $(160.28,\\ 163.72)$ — width $3.44°F$. As confidence level increases from 90% to 95% to 99%, the interval gets progressively wider. More confidence requires a wider net. The center (162°F) stays the same for all three — only the width changes."
            }
          ],
          "final_answer": "(a) 90% CI: $(160.90°F,\\ 163.10°F)$. (b) 95% CI: $(160.69°F,\\ 163.31°F)$. (c) 99% CI: $(160.28°F,\\ 163.72°F)$. (d) Higher confidence level → wider interval. The point estimate (center) is always $\\bar{x} = 162°F$; only the margin of error changes.",
          "concept_applied": "Confidence level and interval width are in direct tension. You cannot simultaneously have high confidence AND a narrow interval without increasing the sample size. This three-way tradeoff (confidence, precision, sample size) is fundamental to understanding statistical inference."
        }
      ]
    },

    {
      "section_title": "Factors That Affect Interval Width — The Three-Way Tradeoff",
      "introduction": "The width of a confidence interval is determined by three factors: sample size, population variability, and confidence level. Understanding how each factor affects width — and the tradeoffs involved — is one of the most practically important concepts in this section. Researchers must balance these three factors when designing a study.",

      "key_concept": {
        "definition": "Interval width is determined by the margin of error: $ME = z^* \\cdot \\dfrac{\\sigma}{\\sqrt{n}}$. This formula contains all three factors: $z^*$ (confidence level), $\\sigma$ (population variability, which we cannot control), and $n$ (sample size, which we can control). Narrower intervals (more precision) are always preferable when achievable, but they come with tradeoffs.",
        "context": "When a researcher or company asks 'how many people do we need to survey?', they're solving this formula for $n$. Given a desired margin of error and confidence level, there's a specific minimum sample size that achieves it. This is the bridge between confidence intervals (Section 10.6) and margin of error (Section 10.7) — the topics are directly connected."
      },

      "categories": [
        {
          "type": "Factor 1: Sample Size $n$ — The Controllable Factor",
          "description": "Increasing sample size decreases the margin of error and produces a narrower interval. This is the primary tool researchers use to improve precision.",
          "detailed_mechanism": "Since $SE = \\sigma/\\sqrt{n}$, increasing $n$ decreases $SE$ by a factor of $1/\\sqrt{n}$. To cut the margin of error in half, you must quadruple the sample size. To cut it to one-third, you need nine times as many observations. This diminishing return means there's always a cost-benefit calculation: is the gain in precision worth the cost of collecting more data? A sample of $n = 1{,}000$ is a major improvement over $n = 250$, but going from $n = 10{,}000$ to $n = 40{,}000$ gives the same proportional improvement at four times the cost.",
          "examples": [
            {
              "process": "Quadrupling $n$ to Halve the Margin of Error",
              "explanation": "Current: $n = 100$, $\\sigma = 10$, $z^* = 1.96$. $ME = 1.96 \\times 10/\\sqrt{100} = 1.96 \\times 1 = 1.96$. New: $n = 400$. $ME = 1.96 \\times 10/\\sqrt{400} = 1.96 \\times 0.5 = 0.98$. Quadrupling $n$ from 100 to 400 exactly halves the ME from 1.96 to 0.98. This $n \\propto 1/ME^2$ relationship is why large national polls use $n \\approx 1{,}000$ rather than $n \\approx 10{,}000$ — doubling again only reduces error by $\\sqrt{2} \\approx 41\\%$, not worth the cost."
            }
          ]
        },
        {
          "type": "Factor 2: Population Variability $\\sigma$ — The Uncontrollable Factor",
          "description": "More variable populations produce wider intervals for any given sample size and confidence level. This is a property of the population, not something a researcher can change.",
          "detailed_mechanism": "If a population has high variability ($\\sigma$ is large), individuals within the population are very spread out. Any sample drawn from this population will also be spread out, making it harder to pin down the mean precisely. The only way to compensate for high population variability is to collect a larger sample. Researchers sometimes use stratified sampling to reduce effective variability — by analyzing homogeneous subgroups, the within-stratum variability ($\\sigma$) is smaller.",
          "examples": [
            {
              "process": "Comparing Two Populations",
              "explanation": "Population A (machine-made bolts): $\\sigma = 0.1$ mm. Population B (handmade bolts): $\\sigma = 1.2$ mm. With the same $n = 50$ and $z^* = 1.96$: $ME_A = 1.96 \\times 0.1/\\sqrt{50} \\approx 0.028$ mm. $ME_B = 1.96 \\times 1.2/\\sqrt{50} \\approx 0.333$ mm. The handmade bolts require a margin of error 12 times wider — not because of the sampling, but because the population is inherently more variable."
            }
          ]
        },
        {
          "type": "Factor 3: Confidence Level — The Tradeoff Factor",
          "description": "Higher confidence levels require larger critical values $z^*$, which produce wider intervals. You cannot increase confidence without sacrificing precision (unless you also increase $n$).",
          "detailed_mechanism": "The three standard $z^*$ values (1.645, 1.96, 2.576) directly multiply the standard error. Switching from 95% to 99% confidence multiplies the margin of error by $2.576/1.96 \\approx 1.31$ — a 31% wider interval. Switching from 90% to 99% multiplies it by $2.576/1.645 \\approx 1.57$ — a 57% wider interval. The choice of confidence level depends on the stakes: medical/safety applications often require 99%, while social science surveys typically use 95%, and quick pilot studies sometimes use 90%.",
          "examples": [
            {
              "process": "The Three-Way Tradeoff in Action",
              "explanation": "A researcher has a budget for $n = 200$ observations from a population with $\\sigma = 15$. She wants a margin of error below 2.0 with 95% confidence. Check: $ME = 1.96 \\times 15/\\sqrt{200} = 1.96 \\times 1.061 \\approx 2.08$. Just above 2.0! Options: (1) Accept a slightly wider margin of error (2.08). (2) Drop to 90% confidence: $ME = 1.645 \\times 1.061 \\approx 1.75 < 2.0$ ✓ but less confident. (3) Increase $n$: need $ME \\leq 2.0$, so $1.96 \\times 15/\\sqrt{n} \\leq 2.0$ → $\\sqrt{n} \\geq 14.7$ → $n \\geq 216$. This is the three-way tradeoff lived out in practice."
            }
          ]
        }
      ]
    },

    {
      "section_title": "Common Mistakes and How to Avoid Them",
      "introduction": "Confidence intervals are notoriously misinterpreted — even by professional journalists and researchers. These are the errors that appear most consistently on assessments and in real-world misuse of statistics.",

      "key_concept": {
        "definition": "The most common errors involve: incorrect interpretation of the confidence level, wrong formula for the margin of error, forgetting to check conditions, and confusing standard error with standard deviation.",
        "context": "On assessments, interpretation questions are worth as many points as calculation questions. Getting the number right but writing the wrong interpretation costs you credit. Practice the standard phrasing until it's automatic: 'We are [C]% confident that the true [parameter] is between [L] and [U].'"
      },

      "categories": [
        {
          "type": "Mistake 1: Misinterpreting the Confidence Level",
          "description": "The most common and most consequential error. The confidence level is a property of the METHOD, not of the specific interval.",
          "detailed_mechanism": "WRONG interpretations: 'There is a 95% chance the parameter is in this interval.' 'The parameter will be in this interval 95% of the time.' '95% of the data falls in this interval.' CORRECT interpretation: 'We are 95% confident the true parameter is in this interval,' meaning the method used to construct the interval captures the true parameter 95% of the time in repeated sampling.",
          "examples": [
            {
              "process": "The Three Wrong Versions and the One Right Version",
              "explanation": "CI: $(0.48, 0.56)$ for a proportion. Wrong: 'There's a 95% chance $p$ is between 0.48 and 0.56.' Wrong: '$p$ equals 0.52 with 95% certainty.' Wrong: '95% of voters support between 48% and 56% of the time.' CORRECT: 'We are 95% confident that the true population proportion $p$ is between 0.48 and 0.56.'"
            }
          ]
        },
        {
          "type": "Mistake 2: Saying the Interval Is About the Sample, Not the Population",
          "description": "The confidence interval is an estimate of the POPULATION parameter, not a description of the sample. We already know the sample — $\\bar{x}$ or $\\hat{p}$ is certain. The uncertainty is about the population.",
          "detailed_mechanism": "WRONG: 'We are 95% confident that the sample mean is between 11.22 and 13.58 hours.' The sample mean IS 12.4 hours — that's already known. CORRECT: 'We are 95% confident that the true POPULATION mean is between 11.22 and 13.58 hours.' Every confidence interval is a statement about an unknown population parameter.",
          "examples": [
            {
              "process": "Population vs. Sample Language",
              "explanation": "A CI of $(62\\%,\\ 70\\%)$ for voter support. WRONG: 'Between 62% and 70% of our sample supports the candidate.' (We already know the sample proportion — it's 66%.) CORRECT: 'We are 95% confident that between 62% and 70% of ALL voters (the population) support the candidate.'"
            }
          ]
        },
        {
          "type": "Mistake 3: Using Standard Deviation Instead of Standard Error",
          "description": "The margin of error uses the STANDARD ERROR ($SE = \\sigma/\\sqrt{n}$), not the standard deviation ($\\sigma$ alone). Forgetting to divide by $\\sqrt{n}$ is one of the most common calculation errors.",
          "detailed_mechanism": "$\\sigma$ describes how spread out the individual data values are. $SE = \\sigma/\\sqrt{n}$ describes how spread out the sample MEANS are. For a confidence interval, we care about how variable the sample mean is across samples — that's the standard error. Using $\\sigma$ instead of $SE$ produces a margin of error that is $\\sqrt{n}$ times too large.",
          "examples": [
            {
              "process": "The $\\sqrt{n}$ Error",
              "explanation": "$\\bar{x} = 50$, $\\sigma = 10$, $n = 100$, $z^* = 1.96$. Wrong: $ME = 1.96 \\times 10 = 19.6$ → CI: $(30.4,\\ 69.6)$. Correct: $SE = 10/\\sqrt{100} = 1$; $ME = 1.96 \\times 1 = 1.96$ → CI: $(48.04,\\ 51.96)$. Forgetting $\\sqrt{n}$ made the interval almost 10 times wider than it should be!"
            }
          ]
        },
        {
          "type": "Mistake 4: Not Checking Conditions Before Applying the Formula",
          "description": "The z-interval formulas are only valid when specific conditions are met. Applying them blindly to any data — regardless of sample size, sampling method, or distribution shape — gives invalid intervals.",
          "detailed_mechanism": "For proportions: must check $n\\hat{p} \\geq 10$ AND $n(1-\\hat{p}) \\geq 10$. For means: must check $n \\geq 30$ OR that the population is approximately normal. Must always check that sampling was random (otherwise the interval is meaningless — a confidence interval from a biased sample doesn't validly estimate the population parameter no matter how correctly it's calculated).",
          "examples": [
            {
              "process": "Failed Condition",
              "explanation": "A sample of $n = 20$ people, $\\hat{p} = 0.08$ have a rare blood type. Check: $n\\hat{p} = 20 \\times 0.08 = 1.6 < 10$ ✗. The success-failure condition FAILS. Do not compute a z-interval here — the formula is not valid. Report the failure and note that a different method is required."
            }
          ]
        },
        {
          "type": "Mistake 5: Concluding That a Value Is or Isn't the Parameter Based on Whether It's in the Interval",
          "description": "A confidence interval gives a RANGE of plausible values — but 'plausible' is not the same as 'certain.' Values outside the interval are unlikely, not impossible.",
          "detailed_mechanism": "If a 95% CI is $(0.52,\\ 0.60)$ and you want to test whether $p = 0.50$, you can say 'the data suggests $p$ is likely above 0.50, since 0.50 is outside our 95% CI.' You cannot say '0.50 is definitely not the true proportion.' Values just outside the interval are not dramatically different from values just inside. The confidence interval gives plausible values, not certain ones.",
          "examples": [
            {
              "process": "Inside vs. Outside the Interval",
              "explanation": "95% CI for mean GPA: $(3.10,\\ 3.50)$. A student claims 'the true mean is 3.55.' Response: 3.55 is outside the 95% CI, so it is not a plausible value at the 95% confidence level — the data is inconsistent with $\\mu = 3.55$. A student claims 'the true mean is 3.48.' Response: 3.48 is inside the CI — it is a plausible value that is consistent with our data."
            }
          ]
        }
      ]
    }
  ],

  "key_terms": [
    "Point Estimate",
    "Interval Estimate",
    "Confidence Interval (CI)",
    "Confidence Level $C$",
    "Margin of Error (ME)",
    "Lower Bound",
    "Upper Bound",
    "Sampling Variability",
    "Sampling Error",
    "Standard Error ($SE$)",
    "$SE_{\\bar{x}} = \\sigma/\\sqrt{n}$",
    "$SE_{\\hat{p}} = \\sqrt{\\hat{p}(1-\\hat{p})/n}$",
    "Critical Value $z^*$",
    "$z^* = 1.645$ (90%)",
    "$z^* = 1.96$ (95%)",
    "$z^* = 2.576$ (99%)",
    "One-Proportion Z-Interval",
    "Z-Interval for a Mean",
    "Success-Failure Condition",
    "$n\\hat{p} \\geq 10$ and $n(1-\\hat{p}) \\geq 10$",
    "Population Proportion $p$",
    "Sample Proportion $\\hat{p}$",
    "Population Mean $\\mu$",
    "Sample Mean $\\bar{x}$",
    "Interval Width",
    "Three-Way Tradeoff (confidence, precision, sample size)",
    "Central Limit Theorem (applied)",
    "Statistical Inference"
  ],

  "summary": "A confidence interval is a range of plausible values for an unknown population parameter, constructed from sample data as: point estimate $\\pm$ margin of error. The point estimate ($\\bar{x}$ or $\\hat{p}$) anchors the center; the margin of error ($ME = z^* \\cdot SE$) determines the width. The confidence level $C$ (typically 90%, 95%, or 99%) reflects how often the method captures the true parameter in repeated sampling — it is a property of the method, not a probability statement about any single interval. The three standard critical values are $z^* = 1.645$ (90%), $z^* = 1.96$ (95%), and $z^* = 2.576$ (99%). For proportions: $ME = z^* \\cdot \\sqrt{\\hat{p}(1-\\hat{p})/n}$, with the success-failure condition $n\\hat{p} \\geq 10$ and $n(1-\\hat{p}) \\geq 10$. For means: $ME = z^* \\cdot \\sigma/\\sqrt{n}$ (use $s$ when $\\sigma$ is unknown and $n \\geq 30$). Interval width is controlled by three factors: larger $n$ narrows the interval, larger $\\sigma$ widens it (uncontrollable), and higher confidence level widens it (a deliberate tradeoff). The correct interpretation is always: 'We are $C\\%$ confident that the true [parameter] is between [L] and [U].' This section connects directly to margin of error (Section 10.7), which formalizes how to solve for required sample size given a desired precision."
}
